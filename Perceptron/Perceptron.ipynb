{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import spline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "Perceptron é um classificador binário linear e representa um neurônio, a estrutura básica de uma rede neural. No perceptron, recebe-se os atributos de entrada da base de treinamento (e.g. as entradas de uma porta lógica AND/OR) e multiplica, cada uma delas, por um peso W, conforme Figura 1. Feito isso, os valores resultantes são somados e passam por uma função de ativação.\n",
    "Nesse notebook, todos os passos para implementação do perceptron serão feitos utilizando Numpy, para isso, 5 etapas deverão ser feitas:\n",
    "1. Inicializaçao dos pesos e bias\n",
    "2. Implementando funções de ativação\n",
    "3. Calculando a saída do neurônio\n",
    "4. Predição\n",
    "5. Treino e avaliação\n",
    "\n",
    "![alt text](imgs/perceptron.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1 - Inicialização dos pesos e bias\n",
    "\n",
    "Ao implementar um perceptron, o primeiro passo é iniciar os pesos em um intervalo pequeno, como [-0.5,0.5] aleatoriamente. O bias quando necessário também deve ser inicializado nessa etapa.\n",
    "\n",
    "Para implementar essa etapa, voçê deve utilizar a função weight_init(num_inputs). Dica: você pode utilizar a [função random do numpy](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.random.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(num_inputs): \n",
    "    \"\"\"\n",
    "    Função que inicializa os pesos e bias aleatoriamente utilizando numpy\n",
    "    Parâmetro: num_inputs - quantidade de entradas X\n",
    "    Retorna: w,b - pesos e bias da rede inicializados\n",
    "    \"\"\"\n",
    "    ### Insira seu código aqui (~2 linhas)\n",
    "    w = np.random.random((1, num_inputs))  - 0.5\n",
    "    b = 2*np.random.random() - 1 \n",
    "    print(w, b)\n",
    "    #print('w: ', w)\n",
    "    return w,b\n",
    "    \n",
    "#weight_init(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2 - Implementação das funções de ativação\n",
    "As funções de ativação definem o intervalo de valores que a saída do neurônio poderá ter. Para redes neurais tradicionais, utiliza-se as funções degrau e sigmoid. Redes neurais profundas podem utilizar as funções ReLU, LeakyReLU e Tangente Hiperbólica para evitar problemas no gradiente.\n",
    "\n",
    "Nsse Notebook, as quatro funções de ativação devem ser implementadas, para verificar a corretude das mesmas, a função visualizeActivationFunc exibe os gráficos correspondentes, as funçoes, suas respectivas saídas e gráfico deverão ser similares ao exposto abaixo: (Dica: utilize a [função exp](https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html) do numpy)\n",
    "* Degrau: saída 0 se menor que 0 e saída 1 caso contrário\n",
    "$$ \\begin{equation}\n",
    "  degrau =\\begin{cases}\n",
    "    1, & \\text{se $x>0$}.\\\\\n",
    "    0, & \\text{caso contrário}.\n",
    "  \\end{cases}\n",
    "\\end{equation} $$\n",
    "![alt text](imgs/degrau.png \"Title\")\n",
    "* Sigmoid: saída entre [0,1]\n",
    "$$ \\begin{equation}\n",
    "  sigmoid = \\frac{1}{1 + e^{-z}}\n",
    "\\end{equation} $$\n",
    "![alt text](imgs/sigmoid.png \"Title\")\n",
    "* Retificadora (Relu): saída 0 caso entrada seja negativa e maior que 1 caso contrário\n",
    "$$ \\begin{equation}\n",
    "  relu = max(0,x)\n",
    "\\end{equation} $$\n",
    "![alt text](imgs/relu.png \"Title\")\n",
    "* Tangente Hiperbólica: saída entre [-1,1]\n",
    "$$ \\begin{equation}\n",
    "  tanh = \\frac{2}{(1+e^{-2*z})} - 1\n",
    "\\end{equation} $$\n",
    "![alt text](imgs/tanh.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_func(func_type, z):\n",
    "    \"\"\"\n",
    "    Função que implementa as funções de ativação mais comuns\n",
    "    Parãmetros: func_type - uma string que contém a função de ativação desejada\n",
    "                z - vetor com os valores de entrada X multiplicado pelos pesos\n",
    "    Retorna: saída da função de ativação\n",
    "    \"\"\"\n",
    "    ### Seu código aqui (~2 linhas)\n",
    "    if func_type == 'sigmoid':\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    elif func_type == 'tanh':\n",
    "        return (2 / (1 + np.exp(-2*z))) - 1\n",
    "    elif func_type == 'relu':\n",
    "        return max(0,z)\n",
    "    elif func_type == 'degrau':\n",
    "        if z > 0:\n",
    "            return 1\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x222c98daba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.arange(-5., 5., 0.2)\n",
    "def visualizeActivationFunc(z):\n",
    "    z = np.arange(-5., 5., 0.2)\n",
    "    func = []\n",
    "    for i in range(len(z)):\n",
    "        func.append(activation_func('relu', z[i]))\n",
    "\n",
    "    plt.plot(z,func)\n",
    "    plt.xlabel('Entrada')\n",
    "    plt.ylabel('Valores de Saída')\n",
    "    plt.show()\n",
    "visualizeActivationFunc(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3 - Cálculo da saída do neurônio¶\n",
    "\n",
    "Com os pesos, bias inicializados e a função de ativação implementada, calcula-se a saída através da equação:\n",
    "\n",
    " $$ \\begin{equation}\n",
    "  Z = W*X + b\n",
    "\\end{equation} $$\n",
    "Feito isso, a saída final é calculada a partir da função de ativação escolhida. Para implementar essa função, você pode utilizar a [função dot do numpy](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) para multiplicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(w,b,X):\n",
    "    \"\"\"\n",
    "    Função que implementa a etapa forward propagate do neurônio\n",
    "    Parâmetros: w - pesos\n",
    "                b - bias\n",
    "                X - entradas\n",
    "    \"\"\"\n",
    "    ### Seu código aqui (~2 linhas)\n",
    "    z = X.dot(p)\n",
    "    out = z + b\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4 - Predição\n",
    "De posse da saída, deve-se avaliar o sucesso da mesma definindo-se um limiar. Para problemas binários, pode-se estabelecer o limiar em 0.5, de forma que abaixo disso a saída é 0 e 1 caso contrário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(out):\n",
    "    \"\"\"\n",
    "    Função que aplica um limiar na saída\n",
    "    Parâmetro: y - saída do neurònio\n",
    "    \"\"\"\n",
    "    ### Seu código aqui (~1 linha)\n",
    "    return 0 if y<0.5 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 5 - Treino e Avaliação\n",
    "\n",
    "Durante o treinamento, a saída é calculada pela função propagate n vezes, onde n é a quantidade de interações do algoritmo. Na primeira interação, os pesos possuem valores pré-definidos pela função de inicialização e são aleatórios após essa interação, as próximas calculam o peso baseado em um erro, calculado a partir da equação:\n",
    "\n",
    " $$ \\begin{equation}\n",
    "  erro = y - ypred\n",
    "\\end{equation} $$\n",
    "\n",
    "Onde y é a saída original do conjunto de dados e y_pred as saidas calculadas. Dado o erro, os pesos são atualizados a partir da equação:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "  w += erro*taxa-de-aprendizado*X\n",
    "\\end{equation} $$\n",
    "\n",
    " \n",
    "Onde X é o conjunto de entrada e a taxa de aprendizagem é um parâmetro de otimização que possui seus valorse variando entre [0,1]. Recomenda-se o uso de taxas de aprendizagem medianas para problemas com redes neurais tradicionais simples (como 0.2-0.5) e taxas de aprendizagem menores para redes neurais profundas (acima de 0.02)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x,y, num_interaction, learning_rate):\n",
    "    \"\"\"\n",
    "    Função que implementa o loop do treinamento \n",
    "    Parâmetros: x - entrada da rede \n",
    "                y - rótulos/labels\n",
    "                num_interaction - quantidade de interações desejada para a rede convergir\n",
    "                learning_rate - taxa de aprendizado para cálculo do erro\n",
    "    \"\"\"\n",
    "    #Passo 1 - Inicie os pesos e bias (~1 linha)\n",
    "    w,b = weight_init(x)\n",
    "    #Passo 2 - Loop por X interações\n",
    "    for j in range(num_interaction):\n",
    "        # Passo 3 -  calcule a saída do neurônio (~1 linha)\n",
    "        y_pred = foward(w, b, x)\n",
    "        # Passo 4 - calcule o erro entre a saída obtida e a saída desejada nos rótulos/labels (~1 linha)\n",
    "        erro = y - y_pred \n",
    "        # Passo 5 - Atualize o valor dos pesos (~1 linha)\n",
    "        # Dica: você pode utilizar a função np.dot e a função transpose de numpy \n",
    "        w += erro * learning_rate * x  \n",
    "        \n",
    "    # Verifique as saídas\n",
    "    print('Saída obtida:', y_pred)\n",
    "    print('Pesos obtidos:', w)\n",
    "\n",
    "    #Métricas de Avaliação\n",
    "    y_pred = predict(y_pred)\n",
    "    print('Matriz de Confusão:')\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print('F1 Score:')\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1c89fe94c18c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mentradas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msaidas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mperceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentradas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaidas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-76d2226418f2>\u001b[0m in \u001b[0;36mperceptron\u001b[1;34m(x, y, num_interaction, learning_rate)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#Passo 1 - Inicie os pesos e bias (~1 linha)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#Passo 2 - Loop por X interações\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_interaction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1c912adbf536>\u001b[0m in \u001b[0;36mweight_init\u001b[1;34m(num_inputs)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \"\"\"\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m### Insira seu código aqui (~2 linhas)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.random_sample\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont0_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "entradas = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "saidas = np.array([0, 0, 0, 1])\n",
    "perceptron(x.shape[1], saidas, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
